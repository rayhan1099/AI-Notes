
cheryl ainoa - evp technology
- built a gateway that handles
	- caching
	- model switching
	- cost tracking
	- log tracking
	- "anything they need to handle internally"
- in response to responsible AI pledge


matt prince
- 100 GPU cities by end of this yr, 300 GPU cities by next year
- not interested in GPUs for training
- interested in using user journey behavior data from cloudflare
	- to offer navigation for training
	- to refine existing models or train brand new models
	- how to deploy them
- support for llmops products
- "killer feature of cloudflare is ability to take something and have it run everywhere"
	- databases: strong consistency guarantees over remote distances
	- fundamentally are a network
	- one type of server per generation, one a year, now on gen 13
		- during gen 7: having gpus make sense
		- dont buy from ibm/dell etc, go direct to ODMs
		- in gen7 - spent money to put extra PCI slot on motherboards
		- waiting for the right time
		- building relationship with other gpu vendors
			- amd processor is faster, excess capacity
			- arm cpus across network
		- gen14 - every one have multiple gpus built into it